{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Abhishek-Thakur-Training-Language-Models-on-TPUs-from-scratch.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"QKxBqmRHQrcG","colab_type":"text"},"source":["#### In this kernel, I will show you how to train language models, such as BERT, from scratch on TPUs!\n","\n","#### If you like this kernel, consider upvoting it and the associated datasets:\n","\n","- https://www.kaggle.com/abhishek/bert-master\n","- https://www.kaggle.com/abhishek/hindi-oscar-corpus\n","- https://www.kaggle.com/abhishek/bert-base-uncased\n","\n","**Google Bert Github**\n","\n","- https://github.com/google-research/bert\n","\n","**Youtube Video**\n","\n","- https://www.youtube.com/watch?v=s-3zts7FTDA"]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"OLKZiTvcQrcH","colab_type":"code","colab":{}},"source":["!pip install -U tokenizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"dVl9IX2kQrcL","colab_type":"code","colab":{}},"source":["!pip install tensorflow==1.15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wM7CLKBqQrcP","colab_type":"code","colab":{}},"source":["import tokenizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"LWrLkcC8QrcS","colab_type":"code","colab":{}},"source":["bwpt = tokenizers.BertWordPieceTokenizer(\n","    vocab_file=None,\n","    add_special_tokens=True,\n","    unk_token='[UNK]',\n","    sep_token='[SEP]',\n","    cls_token='[CLS]',\n","    clean_text=True,\n","    handle_chinese_chars=True,\n","    strip_accents=True,\n","    lowercase=True,\n","    wordpieces_prefix='##'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"y6bhMUdNQrcV","colab_type":"code","colab":{}},"source":["bwpt.train(\n","    files=[\"../input/hindi-oscar-corpus/hi_dedup_1000.txt\"],\n","    vocab_size=30000,\n","    min_frequency=3,\n","    limit_alphabet=1000,\n","    special_tokens=['[PAD]', '[UNK]', '[CLS]', '[MASK]', '[SEP]']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"o4vqG3N3QrcX","colab_type":"code","colab":{}},"source":["bwpt.save(\"/kaggle/working/\", \"hindi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"iyHFnw1lQrca","colab_type":"code","colab":{}},"source":["cd ../input/bertsrc/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"HH5xIyc8Qrce","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"RyLndbWGQrcg","colab_type":"code","colab":{}},"source":["!python create_pretraining_data.py \\\n","    --input_file=/kaggle/input/hindi-oscar-corpus/hi_dedup_1000.txt \\\n","    --output_file=/kaggle/working/tf_examples.tfrecord \\\n","    --vocab_file=/kaggle/working/hindi-vocab.txt \\\n","    --do_lower_case=True \\\n","    --max_seq_length=128 \\\n","    --max_predictions_per_seq=20 \\\n","    --masked_lm_prob=0.15 \\\n","    --random_seed=42 \\\n","    --dupe_factor=5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"mMqPrts9Qrci","colab_type":"code","colab":{}},"source":["!python run_pretraining.py \\\n","    --input_file=gs://tf-lang-model/*.tfrecord \\\n","    --output_dir=gs://tf-lang-model/model/ \\\n","    --do_train=True \\\n","    --do_eval=True \\\n","    --bert_config_file=/kaggle/input/bert-base-uncased/config.json \\\n","    --train_batch_size=32 \\\n","    --max_seq_length=128 \\\n","    --max_predictions_per_seq=20 \\\n","    --num_train_steps=20 \\\n","    --num_warmup_steps=10 \\\n","    --learning_rate=2e-5 \\\n","    --use_tpu=True \\\n","    --tpu_name=$TPU_NAME"],"execution_count":null,"outputs":[]}]}